{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPoxDZiqMeRK"
      },
      "source": [
        "Implement RITA into jupyter notebook "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ooz4EbHtMad_"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbVMvehROvnJ"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpzP2WOChoky"
      },
      "outputs": [],
      "source": [
        "f_timestamp = '@timestamp'\n",
        "f_src_ip = 'source.ip'\n",
        "f_dst_ip = 'cisco.ftd.security.dst_ip'\n",
        "f_dst_host = 'url.original'\n",
        "f_dst_port = 'cisco.ftd.security.dst_port'\n",
        "f_sent_bytes = 'cisco.ftd.security.responder_bytes'\n",
        "\n",
        "\n",
        "columns_to_filter = [f_timestamp, f_src_ip, f_dst_ip, f_dst_host, f_dst_port, f_sent_bytes]\n",
        "columns_to_groupby = [f_src_ip, f_dst_ip, f_dst_host, f_dst_port] #Group the connect together that are the same. \n",
        "# columns to display after the analysis\n",
        "columns_to_display = ['Score','tsScore','dsScore','conn_count',f_src_ip,f_dst_ip,f_dst_host, f_dst_port,f_sent_bytes,'deltas']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ipJjEiXf9N2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYLGXS1VO1If"
      },
      "source": [
        "Filtering the req columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_K2Jh4tPDiN"
      },
      "source": [
        "Preparing the data for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y4nIxzGPJT9"
      },
      "outputs": [],
      "source": [
        "df = df.loc[:,columns_to_filter]\n",
        "df[f_timestamp] = pd.to_datetime(df[f_timestamp]) #Converting str to datetime\n",
        "df = df.groupby(columns_to_groupby).agg(list)\n",
        "df.reset_index(inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXiRASg2PesF"
      },
      "source": [
        "Cal connection count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NQtJ9iMPfLC"
      },
      "outputs": [],
      "source": [
        "# create a new column 'conn_count', and for each row in the 'timestamp' column, apply a function and assign the returned value to the 'conn_count' column\n",
        "df['ConnectionCount'] = df[f_timestamp].apply(lambda x: len(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfipwl2uPuFx"
      },
      "outputs": [],
      "source": [
        "df = df.loc[df['ConnectionCount'] > 10] #Remove all connection with less then 10 connections, it was choosen because of the small data sample I used, The goal is to reduce the amount of data that need to be processed\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox2aaBPUP-EB"
      },
      "source": [
        "Sorting by timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR21aO5rQAOF"
      },
      "outputs": [],
      "source": [
        "df[f_timestamp] = df[f_timestamp].apply(lambda x: sorted(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybvEbgYnQNV3"
      },
      "source": [
        "Cal time delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUAKDL3zQJ7w"
      },
      "outputs": [],
      "source": [
        "# Convert list into a Series object, get time delta, convert the result back into a list and assign it to the 'deltas' column\n",
        "df['delta_time'] = df[f_timestamp].apply(lambda x: pd.Series(x).diff().dt.seconds.dropna().tolist())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eefFbvAMQaHt"
      },
      "source": [
        "cal time series variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY_vPFglQd44"
      },
      "outputs": [],
      "source": [
        "df['tsLow'] = df['delta_time'].apply(lambda x: np.percentile(np.array(x),25))\n",
        "df['tsMid'] = df['delta_time'].apply(lambda x: np.percentile(np.array(x), 50))\n",
        "df['tsHigh'] = df['delta_time'].apply(lambda x: np.percentile(np.array(x), 75))\n",
        "\n",
        "df['tsBowleyNum'] = df['tsLow'] + df['tsHigh'] - 2 * df['tsMid']\n",
        "df['tsBowleyDen'] = df['tsHigh'] - df['tsLow']\n",
        "\n",
        "# tsSkew should equal zero if the denominator equals zero\n",
        "# bowley skew is unreliable if Q2 = Q1 or Q2 = Q3\n",
        "df['tsSkew'] = df[['tsLow', 'tsMid', 'tsHigh', 'tsBowleyNum','tsBowleyDen']].apply(\n",
        "    lambda x: x['tsBowleyNum'] / x['tsBowleyDen'] if x['tsBowleyDen'] !=0 and x['tsMid'] != x['tsLow'] and x['tsMid'] != x['tsHigh'] !=0 else 0.0, axis=1\n",
        "    )\n",
        "df['tsMadm'] = df['delta_time'].apply(lambda x: np.median(np.absolute(np.array(x) - np.median(np.array(x)))))\n",
        "df['tsConnDiv'] = df[f_timestamp].apply(lambda x: (x[-1].to_pydatetime() - x[0].to_pydatetime()).seconds / 90)\n",
        "\n",
        "# Time delta score calculation\n",
        "df['tsConnCountScore'] = df.apply(lambda x: 0.0 if x['tsConnDiv'] == 0  else x['ConnectionCount'] / x['tsConnDiv'] if x['ConnectionCount'] / x['tsConnDiv'] < 1.0 else 1.0 , axis=1)\n",
        "df['tsSkewScore'] = 1.0 - abs(df['tsSkew'])\n",
        "df['tsMadmScore'] = df['tsMadm'].apply(lambda x: 0 if 1.0 - (x / 30.0) < 0 else 1.0 - (x / 30.0))\n",
        "df['tsScore'] = (((df['tsSkewScore'] + df['tsMadmScore'] + df['tsConnCountScore']) / 3.0) * 1000) / 1000\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkhEiGzVWyC"
      },
      "source": [
        "Varibles for data size dispersion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYMkISrQVM1w"
      },
      "outputs": [],
      "source": [
        "df['dsLow'] = df[f_sent_bytes].apply(lambda x: np.percentile(np.array(x), 25))\n",
        "df['dsMid'] = df[f_sent_bytes].apply(lambda x: np.percentile(np.array(x), 50))\n",
        "df['dsHigh'] = df[f_sent_bytes].apply(lambda x: np.percentile(np.array(x), 75))\n",
        "df['dsBowleyNum'] = df['dsLow'] + df['dsHigh'] - 2 * df['dsMid']\n",
        "df['dsBowleyDen'] = df['dsHigh'] - df['dsLow']\n",
        "\n",
        "\n",
        "# dsSkew should equal zero if the denominator equals zero\n",
        "# bowley skew is unreliable if Q2 = Q1 or Q2 = Q3\n",
        "df['dsSkew'] = df[['dsLow','dsMid','dsHigh','dsBowleyNum','dsBowleyDen']].apply(\n",
        "    lambda x: x['dsBowleyNum'] / x['dsBowleyDen'] if x['dsBowleyDen'] != 0 and x['dsMid'] != x['dsLow'] and x['dsMid'] != x['dsHigh'] else 0.0, axis=1\n",
        "    )\n",
        "df['dsMadm'] = df[f_sent_bytes].apply(lambda x: np.median(np.absolute(np.array(x) - np.median(np.array(x)))))\n",
        "\n",
        "\n",
        "# Data size score calculation of sent bytes\n",
        "df['dsSkewScore'] = 1.0 - abs(df['dsSkew'])\n",
        "df['dsMadmScore'] = df['dsMadm'].apply(lambda x: 0 if x/ 128.0 < 0 else x/ 128.0)\n",
        "df['dsSmallnessScore'] = df['dsMid'].apply(lambda x: 0 if 1.0 - x / 8192.0 < 0 else 1.0 - x / 8192.0)\n",
        "df['dsScore'] = (((df['dsSkewScore'] + df['dsMadmScore'] + df['dsSmallnessScore']) / 3.0) * 1000) / 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSYXgJjiVchq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Overal Score calculation\n",
        "df['Score'] = (df['dsScore'] + df['tsScore']) / 2\n",
        "\n",
        "df.sort_values(by= 'Score', ascending=False, inplace=True, ignore_index=True)\n",
        "df.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbI9TpjbW7P-"
      },
      "outputs": [],
      "source": [
        "df.loc[df['Score'] > 0.80, columns_to_display]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Network traffic beacon analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "14392d187e511ec6ca529e86242db1c899912bb8aca1673fdbe0322d49c6004e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
